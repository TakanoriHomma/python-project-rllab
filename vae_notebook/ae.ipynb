{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d9a717-39fd-4667-8525-a3b07147b889",
   "metadata": {},
   "source": [
    "# オートエンコーダ（AE）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35923f4c-3729-4b7a-818a-4605b8389985",
   "metadata": {},
   "source": [
    "## モジュールインポート・クラス定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed778b1-61c2-4780-86c7-0609a6384db3",
   "metadata": {},
   "source": [
    "### モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3f58f4-8d86-4ea2-83ec-d9dccfe8aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3c0e0-813c-484f-944f-08e0b3d96255",
   "metadata": {},
   "source": [
    "### データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc943165-1f24-4c7c-860f-72f7e8ee4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# traindata = torchvision.datasets.MNIST(root='./data', train=True,download=True,transform=transform)\n",
    "# trainloader = DataLoader(traindata,batch_size = 64)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=False,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "# fig, label = train_dataset[0]\n",
    "# print(f'fig shape : {fig.size()}, label : {label}')\n",
    "\n",
    "# fig, axes = plt.subplots(1, 5)\n",
    "# for i in range(5):\n",
    "#     axes[i].imshow(train_dataset[i][0].view(-1, 28), cmap='gray')\n",
    "#     axes[i].axis(\"off\")\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "# for i in range(10):\n",
    "#     ax = fig.add_subplot(2,5,i+1)\n",
    "#     ax.imshow(data[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac185de3-5fc8-401a-8560-030768b1bf34",
   "metadata": {},
   "source": [
    "### ハイパパラメータ・各種設定  \n",
    "- num_epochs  \n",
    "  エポック数\n",
    "- batch_size  \n",
    "  バッチサイズ\n",
    "- learning_rate  \n",
    "  学習率\n",
    "- hidden_size  \n",
    "  隠れ層のサイズ\n",
    "\n",
    "乱数をシードで固定．また，GPU使用に関して設定．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac85525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "hidden_size = 2\n",
    "\n",
    "# 乱数シード設定\n",
    "torch.manual_seed(1205)\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e1e57-cac3-41e6-8ec1-d836a421ab64",
   "metadata": {},
   "source": [
    "### AEクラスの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b7d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オートエンコーダのクラス\n",
    "# エンコーダ・デコーダを含めたもの．別々に分けて実装し，forwardで一つにしている．\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # エンコーダ\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, hidden_size),\n",
    "            # nn.Linear(28 * 28, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, 64),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(64, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # デコーダ\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(hidden_size, 64),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(64, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, 28 * 28),\n",
    "            nn.Linear(hidden_size, 28 * 28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd8771-9461-4d07-b730-111ced4269d5",
   "metadata": {},
   "source": [
    "### 学習データセットの作成\n",
    "MNISTデータセット読み込み，前処理を行ってデータセットを作成．テストデータセットは後ほど作成．\n",
    "ここではtransforms.Compose()関数を使用して，データの前処理を複数の変換（transform）を順に適用するパイプラインとして定義．\n",
    "- transforms.ToTensor():  \n",
    "画像データをテンソルに変換．MNISTの画像データは0から255の範囲の整数値で表されているが，\n",
    "ToTensor()変換によって0から1の範囲の浮動小数点テンソルに変換される．  \n",
    "これにより，画像データが[0, 255]の範囲から[0.0, 1.0]の範囲に正規化される．\n",
    "\n",
    "- transforms.Normalize((mean,), (sigma,)):  \n",
    "値の正規化に伴い，テンソルの各チャネルごとに平均と標準偏差を正規化．\n",
    "MNISTの場合，画像データは単一チャネルのグレースケール画像なので，正規化のためのパラメータは平均(mean,)と標準偏差(sigma,)となる．\n",
    "この変換により，各ピクセルの値が平均mean，標準偏差sigmaの範囲に変換される．\n",
    "\n",
    "これでMNISTの画像データがテンソルに変換され，範囲が正規化される．  \n",
    "また，それを用いて以下のオブジェクトを作成．\n",
    "- train_dataset  \n",
    "  用意したパイプラインを使ってMNISTデータセットからデータを作成\n",
    "- train_loader  \n",
    "  学習データセットをミニバッチ単位で取得するためのローダオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454ff8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータセット読み込み，変形してデータセットを作成\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])\n",
    "# 学習データセット\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# 学習データセットをミニバッチ単位で取得するためのローダオブジェクト\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36a15e-864a-4e6a-a0f4-e72f1d815ec1",
   "metadata": {},
   "source": [
    "## 学習・可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afb7c2-4a96-41f8-80d4-867159986517",
   "metadata": {},
   "source": [
    "### インスタンス生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f44c923-2250-4fbe-9700-199bc60feb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オートエンコーダモデルのインスタンスを作成\n",
    "autoencoder = Autoencoder().to(device)\n",
    "\n",
    "# 損失関数とオプティマイザを定義\n",
    "criterion = nn.MSELoss()# 損失関数\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate) # 池田オプティマイza\n",
    "\n",
    "# criterion = nn.MSELoss()  # 損失関数\n",
    "# optimizer = optim.SGD(autoencoder.parameters(), lr=learning_rate)  # オプティマイza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e6ead-b2a5-4b43-9b8a-ce2339bba562",
   "metadata": {},
   "source": [
    "### lossの計算と順伝搬・逆伝搬\n",
    "\n",
    "- outputs:\n",
    "オートエンコーダの出力（再構成データ）\n",
    "- inputs:\n",
    "outputsに対応する入力データ\n",
    "- criterion:\n",
    "inputとoutputsを比較し，適切な損失を計算．\n",
    "\n",
    "オートエンコーダでは一般的には平均二乗誤差（Mean Squared Error, MSE）が用いられる．  \n",
    "MSEは，各ピクセルの予測値と真の値の二乗誤差を平均した値である．     \n",
    "再構成データと元のデータのピクセル間の差を求め，その差を最小化することでオートエンコーダをトレーニングする．  \n",
    "PyTorchでは、nn.MSELoss()クラスを使用してMSEを計算することができる．  \n",
    "その他の損失関数としてはクロスエントロピー損失や二値交差エントロピー損失などがあるが，今回は用いない．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7eac2d3-1820-4f58-a4b5-23b139525d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6939064730713362\n",
      "Epoch [2/10], Loss: 0.4693616940649842\n",
      "Epoch [3/10], Loss: 0.36220620534440345\n",
      "Epoch [4/10], Loss: 0.30917679872721243\n",
      "Epoch [5/10], Loss: 0.2801748344829596\n",
      "Epoch [6/10], Loss: 0.26299368966617054\n",
      "Epoch [7/10], Loss: 0.2522607716415991\n",
      "Epoch [8/10], Loss: 0.24532521584394898\n",
      "Epoch [9/10], Loss: 0.24075268920677811\n",
      "Epoch [10/10], Loss: 0.23769893007936763\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = .0\n",
    "    for images, _ in train_loader:\n",
    "        # オートエンコーダに入力するため，データを平滑化\n",
    "        # バッチサイズを保持したまま，残りの次元を平滑化して一次元のベクトルに変換\n",
    "        input = images.view(images.size(0), -1).to(device)\n",
    "        \n",
    "        \"\"\"\n",
    "        model.train()    # 訓練モードにする\n",
    "        preds = model(x) # モデルの出力を取得\n",
    "        loss = criterion(preds, x) # 入力xと復元predsの誤差を取得\n",
    "        optimizer.zero_grad()      # 勾配を0で初期化\n",
    "        loss.backward()  # 誤差の勾配を計算\n",
    "        optimizer.step() # パラメーターの更新\n",
    "        train_loss += loss.item() # 誤差(損失)の更新\n",
    "        \"\"\"\n",
    "        autoencoder.train() \n",
    "        # 順伝播\n",
    "        # 勾配をゼロにリセット\n",
    "        optimizer.zero_grad()\n",
    "        # エンコーダに入力し，出力を得る\n",
    "        outputs = autoencoder(input)\n",
    "        # inputとoutputから損失（MSE）を計算\n",
    "        loss = criterion(outputs, input)\n",
    "        \n",
    "        # 逆伝搬\n",
    "        # 誤差逆伝播（backpropagation）を実行し．\n",
    "        # モデルの各パラメータに対する損失関数の勾配を計算．\n",
    "        # 具体的には，損失関数をバックワード方向に逆伝播し，各パラメータに対する勾配を計算．\n",
    "        # この勾配は各パラメータが損失を最小化する方向にどれだけ移動するべきかを示す．\n",
    "        loss.backward()\n",
    "        # optimizer.step()は，オプティマイザによるパラメータの更新を行う．\n",
    "        # 具体的には，step()メソッドを呼び出すことで，オプティマイザが計算された勾配を使用してモデルのパラメータを更新する．\n",
    "        # これにより，勾配降下法などの最適化アルゴリズムに基づいてパラメータが更新され，モデルが最適なパラメータに近づく．\n",
    "        optimizer.step()\n",
    "\n",
    "        # 各バッチの損失値を変数running_lossに累積\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # エポックごとの損失を表示\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe869f6-c35c-4d07-9388-5d0fae366202",
   "metadata": {},
   "source": [
    "### 訓練済みモデルでエンコード・デコード\n",
    "まず，torchvision.datasets.MNIST()関数を使用してMNISTデータセットのテスト用データを読み込む．\n",
    "引数にはデータセットの保存場所を示すroot，データが訓練データでなくテストデータであることを示すtrain=False，\n",
    "そしてデータの前処理を指定するtransform．\n",
    "download=Trueに設定するとデータがローカルに存在しない場合に自動的にダウンロードされる．\n",
    "\n",
    "次に，torch.utils.data.DataLoader()関数を使用してテストデータセットをバッチ単位で取得するためのデータローダーを作成．\n",
    "データローダーは指定したバッチサイズでデータを分割し，イテレーションごとにバッチを提供する機能を提供．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6425f2fe-58c1-4ada-97da-f5a71f400503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータのエンコードとデコード\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# 最初の4つのテスト画像を取得\n",
    "images, _ = next(iter(test_loader))\n",
    "images = images.view(images.size(0), -1).to(device)\n",
    "\n",
    "# model.eval() # ネットワークを評価モードにする\n",
    "autoencoder.eval() # ネットワークを評価モードにする\n",
    "\n",
    "# テスト画像をエンコード・デコード\n",
    "encoded_images = autoencoder.encoder(images)\n",
    "# decoded_images = autoencoder(images)\n",
    "decoded_images = autoencoder.decoder(encoded_images)\n",
    "# print(decoded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e5f82-b14f-4c80-835e-30c04ab22217",
   "metadata": {},
   "source": [
    "### 出力\n",
    "元の画像とデコードされた画像を可視化する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d9f76f1-a007-464e-93e8-85016ed3f02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(10, 4))\n",
    "\n",
    "for i in range(4):\n",
    "    # 元の画像\n",
    "    axes[0, i].imshow(images[i].view(28, 28).cpu(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # デコードされた画像\n",
    "    axes[1, i].imshow(decoded_images[i].view(28, 28).detach().cpu(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f619bd-a5bc-482c-8eea-ced35747f1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
