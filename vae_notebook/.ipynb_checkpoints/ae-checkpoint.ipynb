{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d9a717-39fd-4667-8525-a3b07147b889",
   "metadata": {},
   "source": [
    "# オートエンコーダ（AE）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35923f4c-3729-4b7a-818a-4605b8389985",
   "metadata": {},
   "source": [
    "## モジュールインポート・クラス定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed778b1-61c2-4780-86c7-0609a6384db3",
   "metadata": {},
   "source": [
    "### モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3f58f4-8d86-4ea2-83ec-d9dccfe8aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3c0e0-813c-484f-944f-08e0b3d96255",
   "metadata": {},
   "source": [
    "### データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc943165-1f24-4c7c-860f-72f7e8ee4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# traindata = torchvision.datasets.MNIST(root='./data', train=True,download=True,transform=transform)\n",
    "# trainloader = DataLoader(traindata,batch_size = 64)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=False,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "# fig, label = train_dataset[0]\n",
    "# print(f'fig shape : {fig.size()}, label : {label}')\n",
    "\n",
    "# fig, axes = plt.subplots(1, 5)\n",
    "# for i in range(5):\n",
    "#     axes[i].imshow(train_dataset[i][0].view(-1, 28), cmap='gray')\n",
    "#     axes[i].axis(\"off\")\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "# for i in range(10):\n",
    "#     ax = fig.add_subplot(2,5,i+1)\n",
    "#     ax.imshow(data[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac185de3-5fc8-401a-8560-030768b1bf34",
   "metadata": {},
   "source": [
    "### ハイパパラメータ・各種設定  \n",
    "- num_epochs  \n",
    "  エポック数\n",
    "- batch_size  \n",
    "  バッチサイズ\n",
    "- learning_rate  \n",
    "  学習率\n",
    "- hidden_size  \n",
    "  隠れ層のサイズ\n",
    "\n",
    "乱数をシードで固定．また，GPU使用に関して設定．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac85525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "hidden_size = 2\n",
    "\n",
    "# 乱数シード設定\n",
    "torch.manual_seed(1205)\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e1e57-cac3-41e6-8ec1-d836a421ab64",
   "metadata": {},
   "source": [
    "### AEクラスの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b7d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オートエンコーダのクラス\n",
    "# エンコーダ・デコーダを含めたもの．別々に分けて実装し，forwardで一つにしている．\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # エンコーダ\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, hidden_size),\n",
    "            # nn.Linear(28 * 28, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, 64),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(64, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # デコーダ\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(hidden_size, 64),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(64, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, 28 * 28),\n",
    "            nn.Linear(hidden_size, 28 * 28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd8771-9461-4d07-b730-111ced4269d5",
   "metadata": {},
   "source": [
    "### 学習データセットの作成\n",
    "MNISTデータセット読み込み，前処理を行ってデータセットを作成．テストデータセットは後ほど作成．\n",
    "ここではtransforms.Compose()関数を使用して，データの前処理を複数の変換（transform）を順に適用するパイプラインとして定義．\n",
    "- transforms.ToTensor():  \n",
    "画像データをテンソルに変換．MNISTの画像データは0から255の範囲の整数値で表されているが，\n",
    "ToTensor()変換によって0から1の範囲の浮動小数点テンソルに変換される．  \n",
    "これにより，画像データが[0, 255]の範囲から[0.0, 1.0]の範囲に正規化される．\n",
    "\n",
    "- transforms.Normalize((mean,), (sigma,)):  \n",
    "値の正規化に伴い，テンソルの各チャネルごとに平均と標準偏差を正規化．\n",
    "MNISTの場合，画像データは単一チャネルのグレースケール画像なので，正規化のためのパラメータは平均(mean,)と標準偏差(sigma,)となる．\n",
    "この変換により，各ピクセルの値が平均mean，標準偏差sigmaの範囲に変換される．\n",
    "\n",
    "これでMNISTの画像データがテンソルに変換され，範囲が正規化される．  \n",
    "また，それを用いて以下のオブジェクトを作成．\n",
    "- train_dataset  \n",
    "  用意したパイプラインを使ってMNISTデータセットからデータを作成\n",
    "- train_loader  \n",
    "  学習データセットをミニバッチ単位で取得するためのローダオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454ff8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータセット読み込み，変形してデータセットを作成\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])\n",
    "# 学習データセット\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# 学習データセットをミニバッチ単位で取得するためのローダオブジェクト\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36a15e-864a-4e6a-a0f4-e72f1d815ec1",
   "metadata": {},
   "source": [
    "## 学習・可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afb7c2-4a96-41f8-80d4-867159986517",
   "metadata": {},
   "source": [
    "### インスタンス生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f44c923-2250-4fbe-9700-199bc60feb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オートエンコーダモデルのインスタンスを作成\n",
    "autoencoder = Autoencoder().to(device)\n",
    "\n",
    "# 損失関数とオプティマイザを定義\n",
    "criterion = nn.MSELoss()# 損失関数\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate) # 池田オプティマイza\n",
    "\n",
    "# criterion = nn.MSELoss()  # 損失関数\n",
    "# optimizer = optim.SGD(autoencoder.parameters(), lr=learning_rate)  # オプティマイza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e6ead-b2a5-4b43-9b8a-ce2339bba562",
   "metadata": {},
   "source": [
    "### lossの計算と順伝搬・逆伝搬\n",
    "\n",
    "- outputs:\n",
    "オートエンコーダの出力（再構成データ）\n",
    "- inputs:\n",
    "outputsに対応する入力データ\n",
    "- criterion:\n",
    "inputとoutputsを比較し，適切な損失を計算．\n",
    "\n",
    "オートエンコーダでは一般的には平均二乗誤差（Mean Squared Error, MSE）が用いられる．  \n",
    "MSEは，各ピクセルの予測値と真の値の二乗誤差を平均した値である．     \n",
    "再構成データと元のデータのピクセル間の差を求め，その差を最小化することでオートエンコーダをトレーニングする．  \n",
    "PyTorchでは、nn.MSELoss()クラスを使用してMSEを計算することができる．  \n",
    "その他の損失関数としてはクロスエントロピー損失や二値交差エントロピー損失などがあるが，今回は用いない．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7eac2d3-1820-4f58-a4b5-23b139525d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7706603874275679\n",
      "Epoch [2/10], Loss: 0.6169773219490865\n",
      "Epoch [3/10], Loss: 0.5069340392470614\n",
      "Epoch [4/10], Loss: 0.43155403127039926\n",
      "Epoch [5/10], Loss: 0.3800519029341781\n",
      "Epoch [6/10], Loss: 0.34417909275748326\n",
      "Epoch [7/10], Loss: 0.318524396432234\n",
      "Epoch [8/10], Loss: 0.29968877965961693\n",
      "Epoch [9/10], Loss: 0.2855391072820245\n",
      "Epoch [10/10], Loss: 0.2747020083449797\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = .0\n",
    "    for images, _ in train_loader:\n",
    "        # オートエンコーダに入力するため，データを平滑化\n",
    "        # バッチサイズを保持したまま，残りの次元を平滑化して一次元のベクトルに変換\n",
    "        input = images.view(images.size(0), -1).to(device)\n",
    "        \n",
    "        \"\"\"\n",
    "        model.train()    # 訓練モードにする\n",
    "        preds = model(x) # モデルの出力を取得\n",
    "        loss = criterion(preds, x) # 入力xと復元predsの誤差を取得\n",
    "        optimizer.zero_grad()      # 勾配を0で初期化\n",
    "        loss.backward()  # 誤差の勾配を計算\n",
    "        optimizer.step() # パラメーターの更新\n",
    "        train_loss += loss.item() # 誤差(損失)の更新\n",
    "        \"\"\"\n",
    "        autoencoder.train() \n",
    "        # 順伝播\n",
    "        # 勾配をゼロにリセット\n",
    "        optimizer.zero_grad()\n",
    "        # エンコーダに入力し，出力を得る\n",
    "        outputs = autoencoder(input)\n",
    "        # inputとoutputから損失（MSE）を計算\n",
    "        loss = criterion(outputs, input)\n",
    "        \n",
    "        # 逆伝搬\n",
    "        # 誤差逆伝播（backpropagation）を実行し．\n",
    "        # モデルの各パラメータに対する損失関数の勾配を計算．\n",
    "        # 具体的には，損失関数をバックワード方向に逆伝播し，各パラメータに対する勾配を計算．\n",
    "        # この勾配は各パラメータが損失を最小化する方向にどれだけ移動するべきかを示す．\n",
    "        loss.backward()\n",
    "        # optimizer.step()は，オプティマイザによるパラメータの更新を行う．\n",
    "        # 具体的には，step()メソッドを呼び出すことで，オプティマイザが計算された勾配を使用してモデルのパラメータを更新する．\n",
    "        # これにより，勾配降下法などの最適化アルゴリズムに基づいてパラメータが更新され，モデルが最適なパラメータに近づく．\n",
    "        optimizer.step()\n",
    "\n",
    "        # 各バッチの損失値を変数running_lossに累積\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # エポックごとの損失を表示\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe869f6-c35c-4d07-9388-5d0fae366202",
   "metadata": {},
   "source": [
    "### 訓練済みモデルでエンコード・デコード\n",
    "まず，torchvision.datasets.MNIST()関数を使用してMNISTデータセットのテスト用データを読み込む．\n",
    "引数にはデータセットの保存場所を示すroot，データが訓練データでなくテストデータであることを示すtrain=False，\n",
    "そしてデータの前処理を指定するtransform．\n",
    "download=Trueに設定するとデータがローカルに存在しない場合に自動的にダウンロードされる．\n",
    "\n",
    "次に，torch.utils.data.DataLoader()関数を使用してテストデータセットをバッチ単位で取得するためのデータローダーを作成．\n",
    "データローダーは指定したバッチサイズでデータを分割し，イテレーションごとにバッチを提供する機能を提供．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6425f2fe-58c1-4ada-97da-f5a71f400503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータのエンコードとデコード\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# 最初の4つのテスト画像を取得\n",
    "images, _ = next(iter(test_loader))\n",
    "images = images.view(images.size(0), -1).to(device)\n",
    "\n",
    "# model.eval() # ネットワークを評価モードにする\n",
    "autoencoder.eval() # ネットワークを評価モードにする\n",
    "\n",
    "# テスト画像をエンコード・デコード\n",
    "encoded_images = autoencoder.encoder(images)\n",
    "# decoded_images = autoencoder(images)\n",
    "decoded_images = autoencoder.decoder(encoded_images)\n",
    "# print(decoded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e5f82-b14f-4c80-835e-30c04ab22217",
   "metadata": {},
   "source": [
    "### 出力\n",
    "元の画像とデコードされた画像を可視化する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d9f76f1-a007-464e-93e8-85016ed3f02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(10, 4))\n",
    "\n",
    "for i in range(4):\n",
    "    # 元の画像\n",
    "    axes[0, i].imshow(images[i].view(28, 28).cpu(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # デコードされた画像\n",
    "    axes[1, i].imshow(decoded_images[i].view(28, 28).detach().cpu(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f619bd-a5bc-482c-8eea-ced35747f1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
